\chapter{Data Collection and Processing}
\label{chapter4}
\thispagestyle{empty}
%\lstset{basicstyle={\ttfamily,\small}, frame=lines}
%I. Introduce methodology
%II. Data
%(a). Table of functions $\{0,1,2\}$
%(b). Table of functions $\{13 data points\}$

%[For each part, describe the Nintegrate and Nmaximize functions and how each of the bounds was calculated.]
\section{Calculation of Splines}
To calculate the cubic splines, we generalized the conditions given in theorem 3.2 and formulated them into Mathematica as code using for loops to iterate the interpolation conditions to minimize redundant code for the splines in $S(K, P_{n})$. We also did the same formulation of the interpolation conditions in order to write the code to construct the splines in $S(MP, P_{n})$. The full codes for each algorithm are provided in appendices A and B.\\\\
In the examples of cubic spine interpolation provided in section 3, we omitted the fact that for small partitions such as $\{0,1,2\}$ one can solve for the coefficients $a_{o},...,d_{1}$ by using Gaussian elimination to solve the system of $8$ linear equations. However, for larger partitions, this can be tedious, hence in the codes we utilized Mathematica's built-in \emph{Solve} function. To solve systems of linear equations, we concatenated each of the vectors into a single matrix for the first argument of the function, and the column vector containing the coefficient variables was used in the second argument. This in turn allowed us to distinguish if the splines generated by each algorithm for the same partition had the same coefficients or not.
\section{Calculation of the $L^2$ and $L^{\infty}$ Error Values}
In this section, we provide a detailed explanation of the data collection process that was used for the Kreyszig and Mhaskar-Pai cubic spline interpolation methods. The Mathematica language served as the basis for all the programs written, including the construction of the cubic splines and the error calculations in the $L^2$ and $L^{\infty}$ norms.
\\\\
For each of the $L^2$ values using definition 2.1, we integrated the difference squared between the function and its spline on the appropriate sub-interval and took the square root of the sum of these integrals using the \emph{Nintegrate} built-in functions. We can take the summation of the square root of each integral since the property of definite integrals allows us to do so. This is symbolically represented by the following equation: \\\\
\centerline{$\displaystyle{\left(\int_{a}^{b} |f(x)-p(x)|^2 \mathrm{d}x\right)^\frac{1}{2} = \left(\int_{x_{0}}^{x_{1}} |f(x)-p_{0}(x)|^2 \mathrm{d}x \right)^\frac{1}{2} + ... + \left(\int_{x_{n-1}}^{x_{n}} |f(x)-p_{n-1}(x)|^2 \mathrm{d}x\right)^\frac{1}{2}}$}.\\\\
To calculate the $L^{\infty}$ values, we know that we must take the maximum value of the sup-norm out of the sub-intervals within $[0,2]$ according to definition 2.2. Hence we took the differences between the original function and the respective cubic spline piece and took the maximum with the \emph{Nmaximize} function in Mathematica to identify which sub-interval provided the maximum value. That is, we calculated \\\\
\centerline{$\displaystyle{\max_{x \in [x_{i}, x_{i+1}]}|f(x)-p_{i}(x)|}$}\\\\
 for $i = 0,1,...,n-1$ and then took the maximum over all $i$. The $L^2$ and $L^{\infty}$ error bounds were calculated using the formulas provided from theorems 3.3 and 3.4 respectively for each of the $L^2$ and $L^{\infty}$ norms. The \emph{Nmaximize} function and its counterpart \emph{Nminimize} use global optimization algorithms such as Nelder-Mead, random search, simulated annealing, and differential evolution in order to approximate the maxima and minima over a given domain \cite{key10}. Meanwhile, the \emph{Nintegrate} function uses special algorithms called \emph{integration strategies} which include singularity handling, oscillatory strategies, and crude Monte Carlo strategies \cite{key11}. More information about these functions and their algorithms can be found in the official Wolfram language documentation.

\section{Calculation of the $L^2$ and $L^{\infty}$ Relative Errors}
In numerical analysis, it is common practice to compute the relative error between approximations and actual values \cite[pg. 17]{key3}. The relative errors for each of the cubic spline interpolation methods were calculated in the same environment as the $L^2$ and $L^{\infty}$ error values. We define the $L^2$ relative error as\\\\
\centerline{$\displaystyle{\frac{\|f(x)-p(x)\|_{2}}{\|f(x)\|_{2}}}$}\\\\
We also define the $L^{\infty}$ relative error in a similar fashion\\\\
\centerline{$\displaystyle{\frac{\|f(x)-p(x)\|_{\infty}}{\|f(x)\|_{\infty}}}$}\\\\
To compute these particular values, we first initialized a variable in the code that would use the \emph{Nintegrate} function to calculate the $L^2$ integral of the original function we are approximating. After retrieving both the error values and norm calculations of each function, we imported the data into an Excel spreadsheet as an auxiliary tool to compute serialized divisions required to obtain the relative error in $L^2$ and $L^{\infty}$. Suppose that we wanted to find the $L^2$ relative error of $S(K, P_{n})$ where the cell E7 holds the $L^2$ norm calculation and F7 contains the $L^2$ value. Then our formula in Excel is written as\\\\
=F7/E7\\\\
To organize the data, we performed a sort of each column in the spreadsheet to order each of the functions' approximations by their relative errors. For example, we first sorted the data by the $L^2$ relative error column to visually inspect which splines performed well in their approximations versus the splines that performed poorly within the partition. Then we repeated the sort with the $L^{\infty}$ column to confirm our results from the $L^{\infty}$ sort. This in turn allowed us to make certain observations and conjectures about the data regarding the accuracy of the cubic spline approximations in each of the norms.
